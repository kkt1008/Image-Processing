{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-NmJ4JNJVDv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import cv2\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import Compose, ToTensor\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "local_zip = '/content/drive/MyDrive/Colab Notebooks/Image_Processing_2025_1/Animals.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/dataset')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "tw22QvWUKM06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RGB_Dataset(torch.utils.data.Dataset): ## make custom dataset\n",
        "  def __init__(self, annotation_path ,root_dir = '/dataset'): # root_dir : The parent directory path of the train and test directories.\n",
        "        'Initialization'\n",
        "        self.data_annotation = pd.read_csv(os.path.join(annotation_path))\n",
        "        self.data_path = self.data_annotation['filepath']\n",
        "        self.labels = self.data_annotation['label']\n",
        "        self.root_dir = root_dir\n",
        "        self.transforms = Compose([\n",
        "            ToTensor()\n",
        "        ])\n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.data_path)\n",
        "\n",
        "  def _preprocessing(self, image):\n",
        "      # This method is called in __getitem__ to preprocess the image.\n",
        "      # 훈련용 이미지 데이터 전처리를 위한 함수. 지금은 사용안함 형식적으로 존재\n",
        "      return image\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        file_path = os.path.join(self.root_dir,self.data_path[index])\n",
        "        input_image = cv2.cvtColor( cv2.imread(file_path), cv2.COLOR_BGR2RGB)\n",
        "        input_image = self._preprocessing(input_image)\n",
        "        pil_image_for_transform = Image.fromarray(input_image) # cv --> PIL for transform\n",
        "        X = self.transforms(pil_image_for_transform) ## data preprocessing\n",
        "        # Load data and get label\n",
        "        y = torch.tensor(self.labels[index]).long()\n",
        "        return X, y # X: img / y: label\n",
        "\n"
      ],
      "metadata": {
        "id": "fkl3fFUsKMuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "## make by using custom dataset class\n",
        "trainset = RGB_Dataset(annotation_path = '/dataset/train_annotation.csv')\n",
        "testset = RGB_Dataset(annotation_path = '/dataset/test_annotation.csv')\n",
        "\n",
        "print('total training images:', len(trainset))\n",
        "print('total test images:', len(testset))\n",
        "print('Torch size:', trainset[0][0].shape)\n",
        "print('rgb 이미지 분류 데이터 확인')\n",
        "\n",
        "## visualize\n",
        "class_names=['Cat','Dog','Tiger','Zebra']\n",
        "for i in range(9):\n",
        "  random_index = random.randint(0,8000)\n",
        "  image, label = trainset[random_index]\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image.permute(1,2,0).numpy())\n",
        "  plt.title(class_names[int(label)])\n",
        "  #plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "n63u_GTaM8th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select random samples\n",
        "train_indices = random.sample(range(len(trainset)),1000)\n",
        "test_indices = random.sample(range(len(testset)),100)\n",
        "\n",
        "# Create subsets using the selected indices\n",
        "train_subset = torch.utils.data.Subset(trainset, train_indices)\n",
        "test_subset = torch.utils.data.Subset(testset, test_indices)\n",
        "\n",
        "print(f'Number of images in the training subset: {len(train_subset)}')\n",
        "print(f'Number of images in the test subset: {len(test_subset)}')"
      ],
      "metadata": {
        "id": "yw3qpQmOKMrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## make model and using GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('device: ', device)"
      ],
      "metadata": {
        "id": "OeoKs53LKMpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "num_cpus = multiprocessing.cpu_count()\n",
        "print(f\"Number of available CPUs: {num_cpus}\")\n"
      ],
      "metadata": {
        "id": "VRK2iow5KMm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo -qq"
      ],
      "metadata": {
        "id": "JxEWx1forxxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "NfxuOC_xr1OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 수정된 BasicLeNet\n",
        "import torch.nn as nn\n",
        "class LeNetCustom(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNetCustom, self).__init__()\n",
        "      # Block 1\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  # 채널 감소\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)  # 스트라이드 2\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.shortcut = nn.Conv2d(32, 64, kernel_size=1, stride=2, padding=0)  # 잔차 연결\n",
        "        # Block 2\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        # Global Average Pooling\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)  # 128x16x16 -> 128x1x1\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 4)  # 4개 클래스, FC 레이어 간소화\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x1 = self.relu1(self.bn1(self.conv1(x)))  # 32x64x64\n",
        "        shortcut = self.shortcut(x1)  # 64x32x32\n",
        "        x2 = self.relu2(self.bn2(self.conv2(x1)))  # 64x32x32\n",
        "        x2 = x2 + shortcut  # 잔차 연결\n",
        "        # Block 2\n",
        "        x3 = self.relu3(self.bn3(self.conv3(x2)))  # 128x16x16\n",
        "        # Global Average Pooling\n",
        "        x = self.gap(x3)  # 128x1x1\n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model1 = LeNetCustom().to(device)\n",
        "summary(model1, (1,64, 64))"
      ],
      "metadata": {
        "id": "ArjXUFXQktOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNetCustum(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=5, stride=2, padding=2), # 96→32, 11→5\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),          # 192→64, 5→3\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=1),          # 256→64\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            # Fully connected 파라미터 대폭 감소\n",
        "            # 마지막 feature map을 1x1로 줄임\n",
        "            nn.AdaptiveAvgPool2d((1,1))\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32*1*1, 8),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(8, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "model2 = AlexNetCustum(num_classes=4).to(device)\n",
        "summary(model2,(1,64,64))"
      ],
      "metadata": {
        "id": "ePG8nnOJKMaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGGCustom(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling 추가\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(32, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model3 = VGGCustom(num_classes=4).to(device)\n",
        "summary(model3,(1,64,64))"
      ],
      "metadata": {
        "id": "4_ohdb5vKMXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## parameters\n",
        "epoch = 40\n",
        "batchsize = 32\n",
        "\n",
        "## dataloader\n",
        "train_loader = torch.utils.data.DataLoader(trainset,\n",
        "                                          batch_size=batchsize,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2,\n",
        "                                          drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(testset,\n",
        "                                          batch_size=1,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2,\n",
        "                                          drop_last=True)\n",
        "\n",
        "## loss function\n",
        "criterion = torch.nn.CrossEntropyLoss() # Cross Entropy\n",
        "\n",
        "## optimizer setting\n",
        "optimizer1 = torch.optim.Adam(model1.parameters(), ## Adam optimizer\n",
        "                            lr=0.001)\n",
        "lr1  = torch.optim.lr_scheduler.StepLR(optimizer1, step_size=5, gamma=0.5)  # 5에폭마다 lr 0.5배\n",
        "\n",
        "optimizer2 = torch.optim.Adam(model2.parameters(), ## Adam optimizer\n",
        "                            lr=0.001)\n",
        "lr2  = torch.optim.lr_scheduler.StepLR(optimizer2, step_size=5, gamma=0.5)  # 5에폭마다 lr 0.5배\n",
        "\n",
        "optimizer3 = torch.optim.Adam(model3.parameters(), ## Adam optimizer\n",
        "                            lr=0.001)\n",
        "lr3  = torch.optim.lr_scheduler.StepLR(optimizer3, step_size=5, gamma=0.5)  # 5에폭마다 lr 0.5배\n",
        "\n"
      ],
      "metadata": {
        "id": "tg0p5A1xQZ-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model training function\n",
        "def train(model, optimizer, train_loader, epoch):\n",
        "  train_loss = []\n",
        "  train_accuracy = []\n",
        "  avg_loss = 0\n",
        "  avg_accuracy = 0\n",
        "  model.train()\n",
        "\n",
        "  for i, (X,y) in enumerate(train_loader):\n",
        "      X,y = X.to(device), y.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      predict = model(X)\n",
        "      loss = criterion(predict, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      _, predicted_classes = torch.max(predict, 1) # Get the predicted class index\n",
        "      correct_predictions = (predicted_classes == y).sum().item()\n",
        "      accuracy = correct_predictions / X.shape[0]\n",
        "\n",
        "      train_accuracy.append(accuracy)\n",
        "      train_loss.append(loss.item())\n",
        "\n",
        "  avg_loss = sum(train_loss) /len(train_loss)\n",
        "  avg_accuracy = sum(train_accuracy) / len(train_accuracy)\n",
        "\n",
        "  print(f'epoch {epoch}) train loss : {avg_loss:.4f} / train_accuracy : {avg_accuracy:.4f}')\n",
        "  return avg_loss, avg_accuracy"
      ],
      "metadata": {
        "id": "aD7FWFZeQ4F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = []\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            predict = model(X)\n",
        "            loss = criterion(predict, y)\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            _, predicted_classes = torch.max(predict, 1)\n",
        "            correct_predictions += (predicted_classes == y).sum().item()\n",
        "            total_samples += y.size(0)\n",
        "\n",
        "    avg_loss = sum(test_loss) / len(test_loss)\n",
        "    accuracy = correct_predictions / total_samples\n",
        "\n",
        "    print(f'Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "-qIcXFAKQ3_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1번 모델 훈련--LeNetCustum\n",
        "train_loss1=[]\n",
        "train_accuracy1=[]\n",
        "for i in range(epoch):\n",
        "  train_loss, train_accuracy = train(model1, optimizer1, train_loader, i)\n",
        "  train_loss1.append(train_loss)\n",
        "  train_accuracy1.append(train_accuracy)\n",
        "  lr1.step()"
      ],
      "metadata": {
        "id": "eLWP4JSdQ38r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model1 loss & accuracy 그래프\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss1)\n",
        "plt.title('Train Loss (Model 1)')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracy1)\n",
        "plt.title('Train Accuracy (Model 1)')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C3cSHhsRQ30p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1번 모델 검증\n",
        "test(model1,test_loader)\n"
      ],
      "metadata": {
        "id": "DvPG4JQ4Q7gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2번 모델 훈련--AlexNetCustum\n",
        "train_loss2=[]\n",
        "train_accuracy2=[]\n",
        "for i in range(epoch):\n",
        "  train_loss, train_accuracy = train(model2, optimizer2, train_loader, i)\n",
        "  train_loss2.append(train_loss)\n",
        "  train_accuracy2.append(train_accuracy)\n",
        "  lr1.step()"
      ],
      "metadata": {
        "id": "eEh1MIauQ7du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model2 loss & accuracy 그래프\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss2)\n",
        "plt.title('Train Loss (Model 2)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracy2)\n",
        "plt.title('Train Accuracy (Model 2)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hDQKTfBWQ7bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2번 모델 검증\n",
        "test(model2,test_loader)\n"
      ],
      "metadata": {
        "id": "hlskolznQ7SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3번 모델 훈련--SimpleLeNet\n",
        "train_loss3=[]\n",
        "train_accuracy3=[]\n",
        "for i in range(epoch):\n",
        "  train_loss, train_accuracy = train(model3, optimizer3, train_loader, i)\n",
        "  train_loss3.append(train_loss)\n",
        "  train_accuracy3.append(train_accuracy)\n",
        "  lr1.step()"
      ],
      "metadata": {
        "id": "6LI_p3MAleiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model3 loss & accuracy 그래프\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss3)\n",
        "plt.title('Train Loss (Model 3)')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracy3)\n",
        "plt.title('Train Accuracy (Model 3)')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rSp2Xiqilefi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3번 모델 검증\n",
        "test(model3,test_loader)\n"
      ],
      "metadata": {
        "id": "RYkucwH6lpRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 히스토그램 계산 함수--오츄 알고리즘에 사용\n",
        "def make_histogram(image, N):\n",
        "  histogram = np.zeros(N)\n",
        "  for i in range(image.shape[0]):\n",
        "    for j in range(image.shape[1]):\n",
        "      histogram[image[i][j]] += 1\n",
        "  return histogram\n",
        "\n",
        "# 임계값 기준으로 이진화 진행 함수--오츄 알고리즘 함수에 사용\n",
        "def make_binary_img(img, T):\n",
        "  binary_image = img.copy()\n",
        "\n",
        "  binary_image[img>=T]=1\n",
        "  binary_image[img<T]=0\n",
        "\n",
        "  return binary_image\n",
        "\n",
        "def otsu_function(image):\n",
        "  hist = make_histogram(image, 256)  # Calculate the histogram\n",
        "  total_pixels = image.shape[0] * image.shape[1]\n",
        "  current_max_variance = 0\n",
        "  optimal_threshold = 0\n",
        "\n",
        "  for threshold in range(1, 256):\n",
        "    # Calculate the number of pixels in each class\n",
        "    foreground_pixels = sum(hist[:threshold])\n",
        "    background_pixels = total_pixels - foreground_pixels\n",
        "\n",
        "    if foreground_pixels == 0 or background_pixels == 0:\n",
        "      continue\n",
        "\n",
        "    # Calculate the mean of each class\n",
        "    foreground_mean = sum([i * hist[i] for i in range(threshold)]) / foreground_pixels\n",
        "    background_mean = sum([i * hist[i] for i in range(threshold, 256)]) / background_pixels\n",
        "\n",
        "    # Calculate the between-class variance\n",
        "    variance = (foreground_pixels / total_pixels) * (background_pixels / total_pixels) * (foreground_mean - background_mean) ** 2\n",
        "\n",
        "    if variance > current_max_variance:\n",
        "      current_max_variance = variance\n",
        "      optimal_threshold = threshold\n",
        "\n",
        "  binary_image = make_binary_img(image, optimal_threshold)\n",
        "  return binary_image\n"
      ],
      "metadata": {
        "id": "KCkzrq43FQiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(torch.utils.data.Dataset): ## make custom dataset\n",
        "  def __init__(self, annotation_path ,root_dir = '/dataset'): # root_dir : The parent directory path of the train and test directories.\n",
        "        'Initialization'\n",
        "\n",
        "        self.data_annotation = pd.read_csv(os.path.join(annotation_path))\n",
        "        self.data_path = self.data_annotation['filepath']\n",
        "        self.labels = self.data_annotation['label']\n",
        "        self.root_dir = root_dir\n",
        "        self.transforms = Compose([\n",
        "            ToTensor()\n",
        "        ])\n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.data_path)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        file_path = os.path.join(self.root_dir,self.data_path[index])\n",
        "        input_image = cv2.cvtColor( cv2.imread(file_path), cv2.COLOR_BGR2RGB)\n",
        "        input_image = self._preprocessing(input_image)\n",
        "\n",
        "        pil_image_for_transform = Image.fromarray(input_image) # cv --> PIL for transform\n",
        "        X = self.transforms(pil_image_for_transform) ## data preprocessing\n",
        "        # Load data and get label\n",
        "        y = torch.tensor(self.labels[index]).long()\n",
        "        return X, y\n",
        "  # 이미지를 읽자마자 수행하는 작업\n",
        "  # 1) grayscale이미지-->히스토그램 평활화\n",
        "  # 2) 64로 리사이즈\n",
        "  # 3) 리사이즈 이미지에서 소벨필터로 에지 검출\n",
        "  # 4) 에지 이미지에서 임계값을 통해 이진화 진행\n",
        "  def _preprocessing(self, image_c):\n",
        "        gray_img = cv2.cvtColor(image_c, cv2.COLOR_RGB2GRAY) # grayscale로 이미지 읽기\n",
        "        hist_img = cv2.equalizeHist(gray_img) # 히스토그램 평황화 진행\n",
        "        resize_img = cv2.resize(hist_img, (64,64), interpolation=cv2.INTER_AREA)\n",
        "        # 리사이즈 이미지에서 에지 검출\n",
        "        '''\n",
        "        sobel_x = cv2.Sobel(resize_img, cv2.CV_64F,1,0,3) # sobel(이미지,x,y,k_size)\n",
        "        sobel_y = cv2.Sobel(resize_img, cv2.CV_64F,0,1,3)\n",
        "        sobel_combined = np.sqrt(sobel_x**2 + sobel_y**2)\n",
        "        sobel_final = np.uint8(np.absolute(sobel_combined))\n",
        "        binary_img = make_binary_img(sobel_final, 100) # 임계값 기준 이진화\n",
        "        '''\n",
        "        canny_img = cv2.Canny(resize_img, 30, 225) # Canny edge detection\n",
        "        binary_img = otsu_function(canny_img) # 리사이즈 이미지 이진화\n",
        "        return binary_img.astype(np.uint8)"
      ],
      "metadata": {
        "id": "jzR5VGYQFXS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "## make by using custom dataset class\n",
        "trainset = CustomDataset(annotation_path = '/dataset/train_annotation.csv')\n",
        "testset = CustomDataset(annotation_path = '/dataset/test_annotation.csv')\n",
        "\n",
        "print('total training images:', len(trainset))\n",
        "print('total test images:', len(testset))\n",
        "print('Torch size:', trainset[0][0].shape)\n",
        "print('임계값 이진화 + Sobel 에지')\n",
        "\n",
        "## visualize\n",
        "class_names=['Cat','Dog','Tiger','Zebra']\n",
        "for i in range(9):\n",
        "  random_index = random.randint(0,8000)\n",
        "  image, label = trainset[random_index]\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image.permute(1,2,0).numpy(),cmap='gray')\n",
        "  plt.title(class_names[int(label)])\n",
        "  #plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "VYBbfN3EFXPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## parameters\n",
        "epoch = 40\n",
        "batchsize = 32\n",
        "\n",
        "## dataloader\n",
        "train_loader = torch.utils.data.DataLoader(trainset,\n",
        "                                          batch_size=batchsize,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2,\n",
        "                                          drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(testset,\n",
        "                                          batch_size=1,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2,\n",
        "                                          drop_last=True)\n",
        "\n",
        "## loss function\n",
        "criterion = torch.nn.CrossEntropyLoss() # Cross Entropy\n",
        "\n",
        "## optimizer setting\n",
        "optimizer1 = torch.optim.Adam(model1.parameters(), ## Adam optimizer\n",
        "                            lr=0.001)\n",
        "lr1  = torch.optim.lr_scheduler.StepLR(optimizer1, step_size=5, gamma=0.5)  # 10에폭마다 lr 0.5배\n",
        "\n",
        "optimizer2 = torch.optim.Adam(model2.parameters(), ## Adam optimizer\n",
        "                            lr=0.001)\n",
        "lr2  = torch.optim.lr_scheduler.StepLR(optimizer2, step_size=5, gamma=0.5)  # 10에폭마다 lr 0.5배\n",
        "\n",
        "optimizer3 = torch.optim.Adam(model3.parameters(), ## Adam optimizer\n",
        "                            lr=0.001)\n",
        "lr3  = torch.optim.lr_scheduler.StepLR(optimizer3, step_size=5, gamma=0.5)  # 10에폭마다 lr 0.5배\n"
      ],
      "metadata": {
        "id": "kcUCQfW3FXNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def invert_pixels(image, p):\n",
        "\n",
        "    image = image.clone()  # 원본 이미지 변경 방지\n",
        "    total_pixels = image.numel()\n",
        "    num_pixels_to_invert = int(total_pixels * (p / 100.0))\n",
        "\n",
        "    # 반전시킬 픽셀의 인덱스를 랜덤으로 선택\n",
        "    indices_to_invert = random.sample(range(total_pixels), num_pixels_to_invert)\n",
        "\n",
        "    # 1D 인덱스를 2D (또는 3D) 인덱스로 변환\n",
        "    # 현재 이미지가 (1, H, W) 형태이므로 1D 인덱스를 2D (H, W) 인덱스로 변환\n",
        "    h, w = image.shape[1], image.shape[2]\n",
        "    rows = [idx // w for idx in indices_to_invert]\n",
        "    cols = [idx % w for idx in indices_to_invert]\n",
        "\n",
        "    # 선택된 픽셀 값 반전 (0 -> 1, 1 -> 0)\n",
        "    for r, c in zip(rows, cols):\n",
        "        image[0, r, c] = 1 - image[0, r, c]\n",
        "\n",
        "    return image\n",
        "\n",
        "def create_inverted_dataset(dataset, p):\n",
        "    inverted_images = []\n",
        "    labels = []\n",
        "    for i in range(len(dataset)):\n",
        "        image, label = dataset[i]\n",
        "        # Invert p% of pixels\n",
        "        inverted_image = invert_pixels(image, p)\n",
        "        inverted_images.append(inverted_image)\n",
        "        labels.append(label)\n",
        "\n",
        "    # Stack the list of tensors into a single tensor\n",
        "    inverted_images_tensor = torch.stack(inverted_images)\n",
        "    labels_tensor = torch.tensor(labels)\n",
        "\n",
        "    # Return as a TensorDataset\n",
        "    class InvertedDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, images, labels):\n",
        "            self.images = images\n",
        "            self.labels = labels\n",
        "        def __len__(self):\n",
        "            return len(self.images)\n",
        "        def __getitem__(self, idx):\n",
        "            return self.images[idx], self.labels[idx]\n",
        "    return InvertedDataset(inverted_images_tensor, labels_tensor)\n",
        "\n"
      ],
      "metadata": {
        "id": "y9VasBTdFLkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "p = 30# % chance of inversion\n",
        "trainset_inverted = create_inverted_dataset(trainset, p)\n",
        "testset_inverted = create_inverted_dataset(testset, p)\n",
        "print(f'Number of images in the inverted training dataset: {len(trainset_inverted)}')\n",
        "print(f'Number of images in the inverted test dataset: {len(testset_inverted)}')\n",
        "print('Torch size:', trainset_inverted[0][0].shape)\n"
      ],
      "metadata": {
        "id": "ZhhuXF4FFC-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_inverted = torch.utils.data.DataLoader(trainset_inverted,\n",
        "                                           batch_size=batchsize,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=2,\n",
        "                                           drop_last=True)\n",
        "test_loader_inverted = torch.utils.data.DataLoader(testset_inverted,\n",
        "                                           batch_size=1,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=2,\n",
        "                                           drop_last=True)\n"
      ],
      "metadata": {
        "id": "nY7mYxUMFC70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: 반전되기 전 이미지와 반전된 이미지를 같이 출력\n",
        "\n",
        "# Visualize original and inverted images side-by-side\n",
        "print(\"\\nVisualizing original and inverted train dataset samples:\")\n",
        "class_names = ['Cat','Dog','Tiger','Zebra']\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(4): # Display 4 pairs of images\n",
        "    random_index = random.randint(0, len(trainset) - 1)\n",
        "\n",
        "    # Get original image\n",
        "    original_image, original_label = trainset[random_index]\n",
        "\n",
        "    # Get corresponding inverted image\n",
        "    inverted_image, inverted_label = trainset_inverted[random_index]\n",
        "\n",
        "    # Display original image\n",
        "    ax = plt.subplot(4, 2, 2*i + 1)\n",
        "    # Permute dimensions for matplotlib (C, H, W) -> (H, W, C) or (H, W) for grayscale\n",
        "    plt.imshow(original_image.permute(1,2,0).squeeze().numpy(), cmap='gray')\n",
        "    plt.title(f'Original\\n{class_names[int(original_label)]}')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Display inverted image\n",
        "    ax = plt.subplot(4, 2, 2*i + 2)\n",
        "    plt.imshow(inverted_image.permute(1,2,0).squeeze().numpy(), cmap='gray')\n",
        "    plt.title(f'Inverted ({p}%) \\n{class_names[int(inverted_label)]}')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iKAxVE9ZFC4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1번 모델 훈련--LeNetCustum\n",
        "train_loss1=[]\n",
        "train_accuracy1=[]\n",
        "for i in range(epoch):\n",
        "  train_loss, train_accuracy = train(model1, optimizer1, train_loader, i)\n",
        "  train_loss1.append(train_loss)\n",
        "  train_accuracy1.append(train_accuracy)\n",
        "  lr1.step()"
      ],
      "metadata": {
        "id": "BKNE6hm3FCob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model1 loss & accuracy 그래프\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss1)\n",
        "plt.title('Train Loss (Model 1)')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracy1)\n",
        "plt.title('Train Accuracy (Model 1)')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m_3NgpDUFudA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1번 모델 검증\n",
        "test(model1,test_loader)\n"
      ],
      "metadata": {
        "id": "bwBymyQiFuN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2번 모델 훈련--simpleLeNet\n",
        "train_loss2=[]\n",
        "train_accuracy2=[]\n",
        "for i in range(epoch):\n",
        "  train_loss, train_accuracy = train(model2, optimizer2, train_loader, i)\n",
        "  train_loss2.append(train_loss)\n",
        "  train_accuracy2.append(train_accuracy)\n",
        "  lr1.step()"
      ],
      "metadata": {
        "id": "oGyUDRG8FuFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model2 loss & accuracy 그래프\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss2)\n",
        "plt.title('Train Loss (Model 2)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracy2)\n",
        "plt.title('Train Accuracy (Model 2)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rzl-7JmgFt8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2번 모델 검증\n",
        "test(model2,test_loader)"
      ],
      "metadata": {
        "id": "bMUSZ73rF0w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3번 모델 훈련--SimpleLeNet\n",
        "train_loss3=[]\n",
        "train_accuracy3=[]\n",
        "for i in range(epoch):\n",
        "  train_loss, train_accuracy = train(model3, optimizer3, train_loader, i)\n",
        "  train_loss3.append(train_loss)\n",
        "  train_accuracy3.append(train_accuracy)\n",
        "  lr1.step()"
      ],
      "metadata": {
        "id": "Vt-coN4sF0ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model3 loss & accuracy 그래프\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss3)\n",
        "plt.title('Train Loss (Model 3)')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracy3)\n",
        "plt.title('Train Accuracy (Model 3)')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uJTQ_QMoF0sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3번 모델 검증\n",
        "test(model3,test_loader)"
      ],
      "metadata": {
        "id": "W29bwRlQF0pU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}